# papers
1. BERT https://arxiv.org/pdf/1810.04805
2. Multi-Stage Document Ranking with BERT https://arxiv.org/pdf/1910.14424
3. Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention https://arxiv.org/pdf/2404.07143
4. Attention is all you Need https://arxiv.org/pdf/1910.14424
